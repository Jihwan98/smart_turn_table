{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "twbc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "trig_word",
      "language": "python",
      "name": "trig_word"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunchul78/alpha_project/blob/master/SVM/twbc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "surprised-supervision"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import *\n",
        "from pandas import Series"
      ],
      "id": "surprised-supervision",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "median-adelaide"
      },
      "source": [
        "spel_index = {' ':0, 'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,'o':15,'p':16,\\\n",
        "              'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26}"
      ],
      "id": "median-adelaide",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CntiRf-uiuO",
        "outputId": "4b1138d9-f002-4f53-f0d1-c0e8ba93f810"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "8CntiRf-uiuO",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "automotive-pizza"
      },
      "source": [
        "# txt 파일 읽기 (trigger word)\n",
        "\n",
        "r = open('/content/drive/Shareddrives/SVRT_Project/data/trigger_word.txt', mode='rt', encoding='utf-8')\n",
        "word = r.read()\n",
        "# word = \"friend\""
      ],
      "id": "automotive-pizza",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ignored-cutting"
      },
      "source": [
        "# 알파벳 number indexing, 총 길이 15 zero padding, \n",
        "\n",
        "def indexing(lst_word):\n",
        "    if len(lst_word) < 16:\n",
        "        index_word = np.zeros(shape=(15,),dtype=int)\n",
        "        index_word = index_word.tolist()\n",
        "        j = 0\n",
        "        for i in lst_word:\n",
        "            index_word[j] = spel_index[i]\n",
        "            j += 1\n",
        "        return index_word\n",
        "    else:\n",
        "        print(\"input under word length 15\")\n",
        "        return None"
      ],
      "id": "ignored-cutting",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "technological-sellers"
      },
      "source": [
        "# indexing 해서 배열로 만들기\n",
        "\n",
        "def to_index(listed):\n",
        "    indexed = []\n",
        "    for i in listed:\n",
        "        indexed.append(indexing(i))\n",
        "    indexed = np.array(indexed)\n",
        "    return indexed"
      ],
      "id": "technological-sellers",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swedish-appreciation"
      },
      "source": [
        "# 한자씩 빼기\n",
        "\n",
        "def one_miss(word):\n",
        "    word_list = []\n",
        "    for i in range(0, len(word)):\n",
        "        w = list(word)\n",
        "        w.pop(i)\n",
        "        w.append(\" \")\n",
        "        word_list.append(w)\n",
        "    word_list = np.array(word_list)\n",
        "    return word_list"
      ],
      "id": "swedish-appreciation",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "circular-frank"
      },
      "source": [
        "# 두자씩 빼기\n",
        "\n",
        "def two_miss(word):\n",
        "    word_list = []\n",
        "    r = int(len(word) * (len(word) - 1) / 2)    # nC2\n",
        "    \n",
        "    while len(word_list) < r:\n",
        "        w = list(word)\n",
        "        a = randrange(0, len(word))\n",
        "        b = randrange(0, len(word) - 1)\n",
        "        w.pop(a)\n",
        "        w.pop(b)\n",
        "        if w not in word_list:    \n",
        "            word_list.append(w)\n",
        "    word_list = np.array(word_list)\n",
        "            \n",
        "    return word_list"
      ],
      "id": "circular-frank",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "passing-cruise"
      },
      "source": [
        "# 기본 단어 + one_miss()\n",
        "\n",
        "def default_word(word):\n",
        "    word_list = np.array([list(word)])\n",
        "    word_list = np.vstack((word_list, one_miss(word)))\n",
        "    \n",
        "    return word_list"
      ],
      "id": "passing-cruise",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "injured-deadline"
      },
      "source": [
        "# 랜덤하게 한자 추가하는 노이즈\n",
        "\n",
        "def make_noise(word_list):\n",
        "    a = word_list.tolist()\n",
        "    \n",
        "    for i in range(0, len(a)):\n",
        "        x = randrange(0, len(a[0]))\n",
        "        y = randrange(0, 27)\n",
        "\n",
        "        a[i].insert(x, list(spel_index.keys())[y])\n",
        "    a = np.array(a)\n",
        "    return a"
      ],
      "id": "injured-deadline",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pleased-enlargement"
      },
      "source": [
        "# change spelling\n",
        "\n",
        "def change_spel(data, spel_from, spel_to):\n",
        "    changed = np.where(data == spel_index[spel_from], spel_index[spel_to], data)\n",
        "    data = np.append(data, changed, axis=0)\n",
        "    data = np.unique(data, axis=0)\n",
        "    \n",
        "    return data"
      ],
      "id": "pleased-enlargement",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "interim-digit"
      },
      "source": [
        "def make_true_data(word):\n",
        "    default_list = default_word(word)  # default\n",
        "    noise_word = make_noise(default_list)  # default 에서 노이즈\n",
        "    \n",
        "    # indexing\n",
        "    indexed_d = to_index(default_list)  \n",
        "    indexed_n = to_index(noise_word)\n",
        "    if len(word) < 6:\n",
        "        d_t_data = indexed_d\n",
        "    else:\n",
        "        two_miss_word = two_miss(word)  # 두자 빼기\n",
        "        indexed_t = to_index(two_miss_word)\n",
        "        d_t_data = np.vstack((indexed_d, indexed_t))\n",
        "        \n",
        "    #  모음 변환 a (1), e (5), i(9), o(15), u(21)\n",
        "    change_a_e = change_spel(d_t_data, \"a\", \"e\")\n",
        "    change_a_i = change_spel(d_t_data, \"a\", \"i\")\n",
        "    change_a_o = change_spel(d_t_data, \"a\", \"o\")\n",
        "    change_a_u = change_spel(d_t_data, \"a\", \"u\")\n",
        "    change_a = np.vstack((change_a_e, change_a_i, change_a_o, change_a_u))\n",
        "\n",
        "    change_e_a = change_spel(d_t_data, \"e\", \"a\")\n",
        "    change_e_i = change_spel(d_t_data, \"e\", \"i\")\n",
        "    change_e_o = change_spel(d_t_data, \"e\", \"o\")\n",
        "    change_e_u = change_spel(d_t_data, \"e\", \"u\")\n",
        "    change_e = np.vstack((change_e_a, change_e_i, change_e_o, change_e_u))\n",
        "    \n",
        "    change_i_a = change_spel(d_t_data, \"i\", \"a\")\n",
        "    change_i_e = change_spel(d_t_data, \"i\", \"e\")\n",
        "    change_i_o = change_spel(d_t_data, \"i\", \"o\")\n",
        "    change_i_u = change_spel(d_t_data, \"i\", \"u\")\n",
        "    change_i = np.vstack((change_i_a, change_i_e, change_i_o, change_i_u))\n",
        "\n",
        "    change_o_a = change_spel(d_t_data, \"o\", \"a\")\n",
        "    change_o_e = change_spel(d_t_data, \"o\", \"e\")\n",
        "    change_o_i = change_spel(d_t_data, \"o\", \"i\")\n",
        "    change_o_u = change_spel(d_t_data, \"o\", \"u\")\n",
        "    change_o = np.vstack((change_o_a, change_o_e, change_o_i, change_o_u))\n",
        "\n",
        "    change_u_a = change_spel(d_t_data, \"u\", \"a\")\n",
        "    change_u_e = change_spel(d_t_data, \"u\", \"e\")\n",
        "    change_u_i = change_spel(d_t_data, \"u\", \"i\")\n",
        "    change_u_o = change_spel(d_t_data, \"u\", \"o\")\n",
        "    change_u = np.vstack((change_u_a, change_u_e, change_u_i, change_u_o))\n",
        "    \n",
        "    d_t_data = np.vstack((change_a, change_e, change_i, change_o, change_u))\n",
        "    d_t_data = np.unique(d_t_data, axis=0)\n",
        "    \n",
        "    # 합치기\n",
        "    true_data = np.vstack((d_t_data, indexed_n))\n",
        "    \n",
        "    # label 넣어주기\n",
        "    true_label = np.ones(shape=(true_data.shape[0],1),dtype=int)\n",
        "    true_data = np.hstack((true_data, true_label))\n",
        "    \n",
        "    return true_data    "
      ],
      "id": "interim-digit",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "consecutive-sunset",
        "outputId": "1a3f1edf-2998-4498-8d06-cec9430c5073"
      },
      "source": [
        "true_data = make_true_data(word)\n",
        "print(true_data.shape)"
      ],
      "id": "consecutive-sunset",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(132, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unlikely-reception"
      },
      "source": [
        "def to_list(text_word):\n",
        "    listed = []\n",
        "    for i in text_word:\n",
        "        listed.append(list(i))\n",
        "    return listed"
      ],
      "id": "unlikely-reception",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "greatest-improvement"
      },
      "source": [
        "# false data\n",
        "\n",
        "false = pd.read_csv(\"/content/drive/Shareddrives/SVRT_Project/data/others.txt\",sep='\\n', names=[\"word\"])\n",
        "\n",
        "def false_data(data):\n",
        "    data.word = data.word.str.lower()\n",
        "    if word in data.word.values:\n",
        "        f_index = data.word[data.word == word].index[0]\n",
        "        false_word = data.word.drop(f_index)\n",
        "    else:\n",
        "        false_word = data.word\n",
        "    return false_word"
      ],
      "id": "greatest-improvement",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reserved-operation"
      },
      "source": [
        "false_word = false_data(false)\n",
        "false_data_indexed = to_index(to_list(false_word))"
      ],
      "id": "reserved-operation",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seven-setup"
      },
      "source": [
        "# True 데이터에서 생성된 데이터 중 False 데이터에 있는 것 삭제\n",
        "\n",
        "false_data_word = false_data_indexed.tolist()\n",
        "true_data_word = np.delete(true_data, -1, 1).tolist()\n",
        "\n",
        "for i in true_data_word:\n",
        "    if i in false_data_word:\n",
        "        d_index = false_data_word.index(i)\n",
        "        false_data_word.pop(d_index)\n",
        "        \n",
        "false_data_word = np.array(false_data_word)"
      ],
      "id": "seven-setup",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seasonal-wallet"
      },
      "source": [
        "false_label = np.zeros(shape=(false_data_word.shape[0],1),dtype=int)\n",
        "false_data = np.hstack((false_data_word, false_label))"
      ],
      "id": "seasonal-wallet",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "distant-lambda"
      },
      "source": [
        "np.random.shuffle(true_data)\n",
        "np.random.shuffle(false_data)\n",
        "\n",
        "train_true = true_data[:-20]\n",
        "test_true = true_data[-20:]\n",
        "\n",
        "np.random.shuffle(false_data)\n",
        "train_false = false_data[:-750]\n",
        "test_false = false_data[-750:]\n"
      ],
      "id": "distant-lambda",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "through-peter"
      },
      "source": [
        "train_data = np.vstack((train_true, train_false))\n",
        "test_data = np.vstack((test_true, test_false))"
      ],
      "id": "through-peter",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "banned-rouge"
      },
      "source": [
        "np.random.shuffle(train_data)\n",
        "np.random.shuffle(test_data)"
      ],
      "id": "banned-rouge",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "killing-edgar"
      },
      "source": [
        "X_train = np.delete(train_data,-1,1)\n",
        "y_train = train_data[:,-1:]"
      ],
      "id": "killing-edgar",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agricultural-platform"
      },
      "source": [
        "X_test = np.delete(test_data,-1,1)\n",
        "y_test = test_data[:,-1:]"
      ],
      "id": "agricultural-platform",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "proud-integral",
        "scrolled": true,
        "outputId": "31a05c91-e2f2-484e-a636-0fcddd102db2"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC(kernel='rbf', C=8, gamma=0.1)\n",
        " \n",
        "svm_model.fit(X_train, y_train)"
      ],
      "id": "proud-integral",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=8, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cathedral-daily",
        "outputId": "fbb69480-7cf7-4ad8-af74-54d984760815"
      },
      "source": [
        "svm_model.score(X_test, y_test)"
      ],
      "id": "cathedral-daily",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9727272727272728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tutorial-young",
        "scrolled": true,
        "outputId": "f7b8a0f5-15f3-4405-b6e1-18ab2d54fc35"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_test_pred = svm_model.predict(X_test)\n",
        "cf = confusion_matrix(y_test, y_test_pred)\n",
        "print(cf)"
      ],
      "id": "tutorial-young",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[743   7]\n",
            " [ 14   6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "union-pontiac",
        "outputId": "9e2e2bc9-4160-47e8-f5ab-ca34c7acd47f"
      },
      "source": [
        "y_train_pred = svm_model.predict(X_train)\n",
        "cf = confusion_matrix(y_train, y_train_pred)\n",
        "print(cf)"
      ],
      "id": "union-pontiac",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2238    1]\n",
            " [   3  109]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "numerical-jurisdiction",
        "scrolled": true,
        "outputId": "05975bed-954c-448e-e8bf-13d56d922646"
      },
      "source": [
        "a = 'friend'\n",
        "a = indexing(a)\n",
        "\n",
        "test_svm = svm_model.predict(np.array([a]))\n",
        "test_svm"
      ],
      "id": "numerical-jurisdiction",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "communist-chrome"
      },
      "source": [
        ""
      ],
      "id": "communist-chrome",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "confidential-illustration"
      },
      "source": [
        "## augmentation 된 data 출력\n",
        "\n",
        "data = np.delete(true_data,-1,1)\n",
        "\n",
        "def data_txt(data, file_name):\n",
        "    spel_index_s = Series(spel_index, dtype=np.int)\n",
        "    list_data = spel_index_s.index\n",
        "    list_name = spel_index_s.values\n",
        "    num_to_spel = Series(data = list_data, index = list_name)\n",
        "    \n",
        "    data_l = data.tolist()\n",
        "    \n",
        "    for i in data_l:\n",
        "        for j in range(len(i)):\n",
        "            i[j] = num_to_spel[i[j]]\n",
        "            \n",
        "    f = open(\"{}.txt\".format(file_name), 'w')\n",
        "    for i in data_l:\n",
        "        for j in range(len(i)):\n",
        "            f.write(i[j])\n",
        "        f.write(\"\\n\")\n",
        "    f.close()"
      ],
      "id": "confidential-illustration",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "checked-equity"
      },
      "source": [
        "data_txt(data, \"true_data\")"
      ],
      "id": "checked-equity",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reduced-crack"
      },
      "source": [
        ""
      ],
      "id": "reduced-crack",
      "execution_count": null,
      "outputs": []
    }
  ]
}
